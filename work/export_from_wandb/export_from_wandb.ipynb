{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a W&B API object\n",
    "api = wandb.Api()\n",
    "\n",
    "# Replace with your project and entity name\n",
    "entity = \"shunyaist\"\n",
    "project = \"GQCO\"\n",
    "\n",
    "# Fetch the runs from the project\n",
    "runs = api.runs(f\"{entity}/{project}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = []\n",
    "\n",
    "for run in runs:\n",
    "    if 'main' in run.tags or 'tune' in run.tags:\n",
    "        metrics = run.history(samples=1000000)\n",
    "        metrics = metrics[['current_size', 'trainer/global_step', '_runtime']]\n",
    "        metrics.rename(columns={'current_size': 'Size'}, inplace=True)\n",
    "        metrics.rename(columns={'trainer/global_step': 'EpochSum'}, inplace=True)\n",
    "        metrics.rename(columns={'_runtime': 'TimeSum'}, inplace=True)\n",
    "        metrics['WandB-ID'] = run.id\n",
    "        metrics['Size'] = metrics['Size'].apply(lambda x: round(x) if pd.notnull(x) else x).astype('Int64', errors='ignore')\n",
    "        metrics['ABCI-ID'] = json.loads(run.json_config)['job_id']['value']\n",
    "        metrics['#GPU'] = json.loads(run.json_config)['world_size']['value']\n",
    "        metrics['LogFreqAcc'] = json.loads(run.json_config)['log_freq_acc']['value']\n",
    "        metrics['InitCheckpoint'] = json.loads(run.json_config)['init_checkpoint']['value']\n",
    "        metrics['TuneSize'] = json.loads(run.json_config)['tune_size']['value']\n",
    "\n",
    "        save_name = f\"output/{run.id}_metrics.csv\"\n",
    "        metrics.to_csv(save_name, index=False)\n",
    "        csv_files.append(save_name)\n",
    "\n",
    "df = pd.concat([pd.read_csv(f) for f in csv_files], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where current_size is None\n",
    "df_cleaned = df.dropna(subset=['Size'])\n",
    "\n",
    "# Retain rows where (trainer/global_step + 1) % LogFreqAcc == 0\n",
    "df_cleaned.loc[:, 'EpochSum'] = df_cleaned['EpochSum'] + 1\n",
    "df_filtered = df_cleaned[(df_cleaned['EpochSum']) % df_cleaned['LogFreqAcc'] == 0].copy()\n",
    "\n",
    "df_filtered.loc[:, '#Node'] = df_filtered['#GPU'] / 4\n",
    "\n",
    "df_filtered = df_filtered[['ABCI-ID', 'WandB-ID', '#Node', '#GPU', 'Size', 'TuneSize', 'EpochSum', 'TimeSum', 'InitCheckpoint']]\n",
    "\n",
    "df_filtered.to_csv('output/wandb_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
